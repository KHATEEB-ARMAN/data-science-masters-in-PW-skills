{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614c71d4-e09f-44f3-9c6f-9fba3e2ef317",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db10914c-3539-49db-9dd1-7c98f57cb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Centroid-based Clustering.\n",
    "# 2.Density-based Clustering.\n",
    "# 3.Distribution-based Clustering.\n",
    "# 4.Hierarchical Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48dd13d7-66b6-4aa9-b757-c4fe09eb96bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centroid-based clustering organizes the data into non-hierarchical clusters, in contrast to hierarchical clustering defined below.\n",
    "# k-means is the most widely-used centroid-based clustering algorithm. Centroid-based algorithms are efficient but sensitive to initial\n",
    "# conditions and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75d3804b-53d4-4526-93b9-7c354bb23f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density-based clustering connects areas of high example density into clusters. This allows for arbitrary-shaped distributions \n",
    "# as long as dense areas can be connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79d30697-86eb-45d9-9f81-903921c26fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution-based Clustering approach assumes data is composed of distributions, such as Gaussian distributions.\n",
    "# the distribution-based algorithm clusters data into three Gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55669072-7c3b-45b7-be6b-a40911bd2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering creates a tree of clusters. Hierarchical clustering, not surprisingly, is well suited to hierarchical data,\n",
    "# such as taxonomies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9bd016-6756-449c-93c3-fffd91f8ae4b",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602dc0ab-5991-413a-8786-4b9d85238139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering is an Unsupervised Learning algorithm, which groups the unlabeled dataset into different clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cc5ebf-d61f-4b04-a48b-c32e8e755e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here K defines the number of pre-defined clusters that need to be created in the process, as if K=2, there will be two clusters, and for K=3, there will be three clusters, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb6476-8c65-4297-9731-fcb2a5667b1b",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccb18811-a27a-4e34-b6ae-3c700f3364f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imitation 1: K-means requires us to specify the number of clusters a priory.\n",
    "# Limitation 2: K-Means is sensitive towards outlier. Outliers can skew the clusters in K-Means in very large extent.\n",
    "# Limitation 3: K-Means forms spherical clusters only.\n",
    "# limitation 4:Clustering outliers. Centroids can be dragged by outliers, or outliers might get their own cluster instead of being ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601871e9-184b-4e98-a0f7-13ebfda48757",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f98451d-1ffd-4a93-a909-b430ccbe70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Compute clustering algorithm (e.g., k-means clustering) for different values of k. For instance, by varying k from 1 to 10 clusters.\n",
    "# 2.For each k, calculate the total within-cluster sum of square (wss).\n",
    "# 3.Plot the curve of wss according to the number of clusters k.\n",
    "# 4.The location of a bend (knee) and elbow in the plot is generally considered as an indicator of the appropriate number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e8e06-aed1-43bb-aec4-e22993905815",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc5835de-8d0a-43dd-bbb2-0f154a7fe469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means algorithm is very popular and used in a variety of applications such as market segmentation, document clustering, \n",
    "# image segmentation and image compression, etc. The goal usually when we undergo a cluster analysis is either: Get a meaningful\n",
    "# intuition of the structure of the data we're dealing with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9f6d78-9f89-40b1-b8da-3ce31f632ef5",
   "metadata": {},
   "source": [
    "## 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ebc75a4-fca0-4d34-b6c9-9bccf980c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpreting the meaning of k-means clusters boils down to characterizing the clusters. A Parallel Coordinates Plot allows us\n",
    "# to see how individual data points sit across all variables. By looking at how the values for each variable compare across clusters, \n",
    "# we can get a sense of what each cluster represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2276e3f0-c5ba-44c8-8a8f-1ef4f4c1e86a",
   "metadata": {},
   "source": [
    "## 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ab33eb9-a28d-41f0-b8d8-43bca35b09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means has trouble clustering data where clusters are of varying sizes and density. To cluster such data, you need to generalize \n",
    "# k-means as described in the Advantages section. Clustering outliers. Centroids can be dragged by outliers, or outliers might get their \n",
    "# own cluster instead of being ignored."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
