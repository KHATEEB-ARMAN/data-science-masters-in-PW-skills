{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ea0a8a-5860-4857-8452-3c5a65356fd3",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76545d63-5f2d-40fe-a758-e24efe7e8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall: The ability of a model to find all the relevant cases within a data set. Mathematically, we define recall as the number of true\n",
    "#         positives divided by the number of true positives plus the number of false negatives.\n",
    "#vPrecision: The ability of a classification model to identify only the relevant data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff43b531-579e-437e-b006-54e80595f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a classification task, a precision score of 1.0 for a class C means that every item labelled as belonging to class C does indeed belong to \n",
    "# class C (but says nothing about the number of items from class C that were not labelled correctly) whereas a recall of 1.0 means that every \n",
    "# item from class C was labelled as belonging to class C (but says nothing about how many items from other classes were incorrectly also labelled \n",
    "# as belonging to class C)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f2f7a-dffb-40f0-9b47-60b961ccdf5c",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb40add-37c7-45b5-921f-37a9279a9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score is a machine learning evaluation metric that measures a model's accuracy. It combines the precision and recall scores of a model. The accuracy metric computes how many times a model made a correct prediction across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fd9296-4671-4c6e-8c79-f12187212f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea090975-71d4-4b27-ab31-16f0e8d22b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F score is calculated from the precision and recall of the test, where the precision is the number of true positive results divided by the number of all positive results, including those not identified correctly, and the recall is the number of true positive results divided by the number of all samples that should have been identified as positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074bac4a-d538-4ffd-b1b7-565544c0461f",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136dfc74-20af-41b1-af75-b8583a61bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC ROC stands for “Area Under the Curve” of the “Receiver Operating Characteristic” curve. The AUC ROC curve is basically a way of measuring the\n",
    "# performance of an ML model. AUC measures the ability of a binary classifier to distinguish between classes and is used as a summary of the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b56ab27-7009-4802-ae67-990f221d477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification\n",
    "# thresholds. This curve plots two parameters: True Positive Rate. False Positive Rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bdd084-bab1-4612-b643-7cb96074a724",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d023ac9-ab9a-43da-8011-3c40cb1bafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  To evaluate such a model, we can choose any of the various metrics available to us, like Accuracy, Sensitivity, Specificity, Precision, F1 Score,\n",
    "# Probability Threshold, AUC, ROC Curve . It is important that this choice is backed by analytical reasoning.\n",
    "# Often, we choose Model Accuracy to evaluate the model. It’s a popular choice because it is very easy to understand and explain.\n",
    "# Accuracy coincides well with the general aim of building a classification model, i.e. to predict the class of new observations accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e24667-687f-4f4f-a489-4b8ed5046088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two major classes of classification problems: Binary-class and Multi-class.\n",
    "\n",
    "# Binary-class classifications, the given dataset is categorized into two classes. \n",
    "# Multi-class classification,the given dataset is categorized into several classes based on the classification rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730281db-10aa-4979-97e5-95ea3d907400",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4c497a4-8877-4a4a-a88c-dea0b211dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression, by default, is limited to two-class classification problems. Some extensions like one-vs-rest can allow logistic\n",
    "# regression to be used for multi-class classification problems, although they require that the classification problem first be transformed\n",
    "# into multiple binary classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb4a9182-23ca-476c-bb5c-31c411b7eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, for a 3 class classification, if the probability of one class is 0.6, this implies the sum of the probabilities of the other\n",
    "# two classes must equal 0.4. The output probability of each class from softmax function is translated into a prediction of the label and then \n",
    "# compared to the true label of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de394f38-557e-414e-ac02-fcc1b60d5405",
   "metadata": {},
   "source": [
    "## 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36b7ac5d-fbbe-4232-910a-aec9f1c9c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "# Loading the data\n",
    "# Feature Engineering\n",
    "# Text processing\n",
    "# Exploring Multi-classification Models\n",
    "# Compare Model performance\n",
    "# Evaluation\n",
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4714dc0-216a-40a5-a214-4d33c8a1366d",
   "metadata": {},
   "source": [
    "## 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45a36f37-1969-4551-b6db-3264761939fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model deployment is the process of putting machine learning models into production. This makes the model's predictions available to users,\n",
    "# developers or systems, so they can make business decisions based on data, interact with their application (like recognize a face in an image)\n",
    "# and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d219a816-87fa-49a7-8670-e5711b7ebc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalability: A machine learning model may work well on a small dataset, but it needs to be deployed in order to scale up to handle larger \n",
    "# volumes of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae9aaa-967f-4597-b116-c5925ba98469",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "735f9d75-806f-47cf-8a44-6b2e2a4f8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A multi-cloud model can include the use of a hybrid cloud, but it relies on more than a single public cloud. For example, a company may\n",
    "# choose to store sensitive data in their on-premise datacenter, leverage one public cloud provider for the “IaaS” services and a second public \n",
    "# cloud provider for their “SaaS” services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fdae59-dea2-4297-a56f-dd8ba4885300",
   "metadata": {},
   "source": [
    "## 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15e85daf-6ba5-482d-8269-efdd354531b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ability To Pick and Choose.\n",
    "# Gives You the Control. \n",
    "# Better Service Reach. \n",
    "# Less Downtime Overall. \n",
    "# More Cost-Effective. \n",
    "# More Confusing Payments. \n",
    "# Difficult Management.\n",
    "# More Security Risks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
