{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cca637-b083-42da-8e35-6f8633b744f2",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f974783-e255-4426-bae6-a28ffc96fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A contingency table consists of a collection of cells containing counts (e.g., of people, establishments, or objects, such as events).\n",
    "# The cells are most often organized in the form or cross-classifications corresponding to underlying categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081e8f59-6e24-4890-baec-38defc2f4637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix.\n",
    "# Accuracy, Recall, Precision.\n",
    "# F1 Score.\n",
    "# Receiving Operating Characteristics(ROC),Area under the Curve(AUC)\n",
    "# Log Loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59983420-d020-43f5-ba80-884548bd8512",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f1827fb-5bcb-4f87-8c4f-776bcdc6dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the difference is that Confusion Matrix is used to evaluate the performance of a classifier, and it tells how accurate a\n",
    "# classifier is in making predictions about classification, and contingency table is used to evaluate association rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b52065e-b620-4c91-8349-5873f53994c8",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570f233d-6e76-42a7-a2e8-bb3b181e8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrinsic evaluation is also called task-based evaluation and captures how useful the model is in a particular task\n",
    "# that is used in downstream applications. Entropy, Cross entropy, and Perplexity are common metrics for evaluating the\n",
    "# performance of language models in NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e29b14-7ed9-405a-8889-09fb9a70a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditionally, language model performance is measured by perplexity, cross entropy, and bits-per-character (BPC). \n",
    "# As language models are increasingly being used as pre-trained models for other NLP tasks, they are often also evaluated\n",
    "# based on how well they perform on downstream tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6361db-1418-4281-8ef3-5f591e1b9aba",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "075c4045-ea85-41ad-8841-0cd3c86254a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In intrinsic evaluation, system output is evaluated against the pre-determined ground truth (reference text) whereas in\n",
    "# extrinsic evaluation quality of system output is assessed based on its impact on the performance of other NLP systems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0317746-aafb-4a8f-aa3c-2c7dc0442bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ob- viously, a requirement is that the intrinsic evaluation has a positive correlation with the final task performance.\n",
    "# Extrinsic evaluation of word vectors is the evaluation of a set of word vectors generated by an embedding technique on the real task at hand.\n",
    "# These tasks are typically elaborate and slow to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88078e8-bea9-4d2c-85c8-d75c9cd0ea39",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c449af-5ac6-40ff-97ec-118df4ff3d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A confusion matrix is a table that summarizes the performance of a machine learning classifier by comparing its predicted and actual labels.\n",
    "# It is a useful tool to evaluate how well your model can distinguish between different classes and identify its strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b09bb6df-761c-4507-b911-42c5733f7f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A confusion matrix represents the prediction summary in matrix form. It shows how many prediction are correct and incorrect per class.\n",
    "# It helps in understanding the classes that are being confused by model as other class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7e7344-97e9-446c-a964-4a574c72e126",
   "metadata": {},
   "source": [
    "## 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f711dddb-103b-4800-ac22-ac6a19229f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically, we measured the differences between the sum squared distance of the data between the cluster and data within the internal cluster.\n",
    "# The higher the Calinski-Harabasz Index score, the better, which means the clusters were well separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11429cb7-5f8c-49a4-bd4e-ccfcdd4ed229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the most common algorithms used in unsupervised learning include: (1) Clustering, (2) Anomaly detection, (3) Approaches for\n",
    "# learning latent variable models. Each approach uses several methods as follows: Clustering methods include: hierarchical clustering,\n",
    "# k-means, mixture models, DBSCAN, and OPTICS algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802ba33-67e6-42bb-803c-da59c9fbbdff",
   "metadata": {},
   "source": [
    "## 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08975dc6-4ef2-463d-8051-548578b0b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy can be misleading or insufficient in some scenarios, such as when the data set is imbalanced or has more than two classes.\n",
    "# For example, if you have a data set of 100 instances where 90 are positive and 10 are negative, and your model predicts all of them as\n",
    "# positive, the accuracy is 0.9 or 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5146c821-c08f-4b20-8548-2e5835ecb218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a downside to focusing on accuracy as a primary metric. The reason is that it treats all classes as equally important and \n",
    "# looks at all correct predictions. In the example above, there are two classes, and the dataset is reasonably balanced. We have multiple \n",
    "# cases of both spam and non-spam emails."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
