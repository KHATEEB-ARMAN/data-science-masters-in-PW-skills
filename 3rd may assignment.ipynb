{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2757b9-f9ac-4de9-a4e5-b1c1751f2439",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c6bbb4-b1ee-41c1-8192-9e23972ffa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus, one of the vital factors that impact the quality of anomaly detection is Feature Selection. \n",
    "# The goal of feature selection is to remove unnecessary and redundant features from a data set in order to improve a \n",
    "# classification algorithm's prediction capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df308bd1-9b1c-4af5-8aba-fe1a5e561355",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64cec78-e65a-484a-9988-2f5bf420f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generally, in order to evaluate the quality of an anomaly detection technique, the confusion matrix and its derived\n",
    "# metrics such as precision and recall are used. These metrics, however, do not take this temporal dimension into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4fffa03-94a8-4f01-9357-ed9a19967a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the common ways to measure anomaly scores is to use the distance or similarity between an instance and the rest of the data.\n",
    "# For example, if you use k-means clustering to group the data into clusters, you can compute the distance between each instance and its\n",
    "# assigned cluster center."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd3a10-3937-4965-b516-29ffa6579bd7",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c36bde-2871-47ff-86f2-a9a39334ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined distance (DBSCAN)—Uses a specified distance to separate dense clusters from sparser noise.\n",
    "# The DBSCAN algorithm is the fastest of the clustering methods, but is only appropriate if there is a very clear Search Distance to use,\n",
    "# and that works well for all potential clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b351d39-bff8-4bb2-b7fc-3ebb461c775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN stands for density-based spatial clustering of applications with noise. It is able to find arbitrary shaped clusters \n",
    "# and clusters with noise (i.e. outliers). The main idea behind DBSCAN is that a point belongs to a cluster if it is close to many \n",
    "# points from that cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4d1ba5-ce2b-4bc6-a85d-e825c0f437cb",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8b8d0f-14a1-42ff-b078-ea3dd0b498f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN requires only two parameters: epsilon and minPoints. Epsilon is the radius of the circle to be created around each\n",
    "# data point to check the density and minPoints is the minimum number of data points required inside that circle for that data \n",
    "# point to be classified as a Core point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0062eb-eb27-41dc-ab75-7954c2a181a2",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc487bfa-da66-4456-9fa4-dc6ce93f1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core points are those that have a minimum number of points (MinPts) within a specified radius ε.\n",
    "# Border points have fewer than MinPts within ε but are in the neighborhood of a core point.\n",
    "# Noise points are all other points that are neither core nor border points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd67719-eac6-4347-b441-3e405d62523e",
   "metadata": {},
   "source": [
    "## 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8a355a-7ff5-4e83-87cc-170d309da87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two key parameters of DBSCAN : eps: The distance that specifies the neighborhoods. Two points are considered to\n",
    "# be neighbors if the distance between them are less than or equal to eps. minPts: Minimum number of data points to define a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605b4425-e92d-42ae-bdce-3ce5e6c63d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main idea behind using clustering for anomaly detection is to learn the normal mode(s) in the data already available \n",
    "# (train) and then using this information to point out if one point is anomalous or not when new data is provided (test)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35760da5-22fa-4e46-8070-76c63ecb8c60",
   "metadata": {},
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b4a171-8548-4a8f-8601-49030983a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The make_circles() function generates a binary classification problem with datasets that fall into concentric circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64cc9ae6-0ebf-48eb-a53c-593e2238c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a large circle containing a smaller circle in 2d. A simple toy dataset to visualize clustering and classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae464bcc-fdcc-4a77-933f-bcd1c6a2ddfa",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77eff4f5-c3f9-45ad-9805-b20c1d6305db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two general types of outlier detection: global and local.\n",
    "\n",
    "# Global outliers fall outside the normal range for an entire dataset.\n",
    "\n",
    "# local outliers may fall within the normalrange for the entire dataset.but outside the normal range for the surrounding data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2403f-c860-4180-a80d-5c5e13ab8f1e",
   "metadata": {},
   "source": [
    "## 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20309fdb-731c-423f-818c-62c1e6a24a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation\n",
    "# of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density \n",
    "# than their neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4323a548-e090-4a85-8e1e-7784555da57e",
   "metadata": {},
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33cbe1c9-0025-4b5f-8143-0b0d0b8a3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest is based on the Decision Tree algorithm. It isolates the outliers by randomly selecting a feature from the given\n",
    "# set of features and then randomly selecting a split value between the max and min values of that feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd462f-9d07-476f-a745-ab419d644c80",
   "metadata": {},
   "source": [
    "## 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f179f3d-47cb-464b-8062-c81d6895a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection is critical for many applications such as healthcare, health insurance, medical diagnosis, predictive analytics,\n",
    "# pattern recognition, intrusion detection, anomaly or defect detection, video surveillance, credit card fraud detection and text mining."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
