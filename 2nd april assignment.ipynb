{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c748f4f8-dae4-432d-89bb-af0417ba3ccf",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e634f851-945f-4506-a3ac-551448caf0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid.\n",
    "# It's essentially a cross-validation technique. The model as well as the parameters must be entered.\n",
    "# After extracting the best parameter values, predictions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c70c0-56bd-4959-a37c-419fa8d80c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search uses a different combination of all the specified hyperparameters and their values and calculates the performance for each combination \n",
    "# and selects the best value for the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08439e10-0690-4c97-92eb-1d35abe6c06a",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c80f5-65ea-44c9-a386-fddb238c79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search: This technique generates evenly spaced values for each hyperparameters and then uses Cross validation to find the optimum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e6e97-df2b-474e-a4e3-010a29c3f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search: This technique generates random values for each hyperparameter being tested and then uses Cross validation to find the optimum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e5409-9dab-4c5f-97ed-e22e44b4ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection is the process of choosing one of the models as the final model that addresses the problem. Model selection is different from\n",
    "# model assessment. For example, we evaluate or assess candidate models in order to choose the best one, and this is model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f919160-cc4d-4516-abd6-6f5ec196fd67",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd11eae-f5b5-4ba0-965b-ae2686bc3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data leakage can be defined as: \"A scenario when ML model already has information of test data in training data, but this information would not\n",
    "# be available at the time of prediction, called data leakage. It causes high performance while training set, but perform poorly in deployment or\n",
    "# production.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73a985-29c7-47ae-985a-0c1366f6963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data can be leaked physically or electronically via hard drives, USB devices, mobile phones, etc., and could be exposed publicly or fall\n",
    "# into the hands of a cyber criminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd537016-b2dd-41b0-b37b-701e91a10922",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378aaf4f-cf50-4716-a84c-0ec209153f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent such leakage, the dataset should be separated into training and testing sets before performing any preprocessing steps.\n",
    "# The preprocessing steps should only be fit on the training dataset and then applied to both the training and test datasets separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aea159b-2748-4a1e-b603-8fb8f8219412",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb5857-6607-450a-8bb0-d017e57e5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A confusion matrix is a table that allows you to visualize the performance of a classification model. You can also use the information in\n",
    "# it to calculate measures that can help you determine the usefulness of the model. Rows represent predicted classifications, while columns\n",
    "# represent the true classes from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b50261-52c7-401e-8e6d-e4855c2f00c0",
   "metadata": {},
   "source": [
    "## 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eeda14d-62d0-438c-a69e-cecf676d1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision measures the accuracy of positive predictions, while recall measures the completeness of positive predictions.\n",
    "\n",
    "# Precision and recall are two evaluation metrics used to measure the performance of a classifier in binary and multiclass classification problems.\n",
    "\n",
    "# Precision measures the accuracy of positive predictions.\n",
    "\n",
    "# while recall measures the completeness of positive predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbb08e-6d61-4e95-9360-47af0d93f296",
   "metadata": {},
   "source": [
    "## 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b5ae2-7636-4552-985d-dea291e23da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matrix compares the actual target values with those predicted by the machine learning model. This gives us a holistic view of how well\n",
    "# our classification model is performing and what kinds of errors it is making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e5b31-2d07-49d1-a481-84d557883d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Positives (TP): The model predicted positive and the actual label is positive.\n",
    "# True Negative (TN): The model predicted negative and the actual label is negative.\n",
    "# False Positive (FP): The model predicted positive and the actual label was negative.\n",
    "# False Negative (FN): The model predicted  negative and the actual label was positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d01286-4c3c-46d1-9760-22aa2aaa6cf7",
   "metadata": {},
   "source": [
    "## 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fe1d1-88d5-46f1-8d88-b3492a92c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Accuracy (ACC),\n",
    "# 2.precision (P).\n",
    "# 3.sensitivity (Sn).\n",
    "# 4.specificity (Sp).\n",
    "# 5.F-score values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79125902-68ff-4187-bc03-6c1a1daaf1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy:   (TP+TN)/(TP+FP+FN+TN)\n",
    "# Precision:  TP/(TP+FP).\n",
    "# Recall:     TP/(TP+FN).\n",
    "# F1 score:   2(p*r)/(p+r) # p=precision,r=recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528fed00-f198-4627-b8d3-43d657e0dc5c",
   "metadata": {},
   "source": [
    "## 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb28b3-0b3d-48a1-baac-c14cd776ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A confusion matrix is a performance evaluation tool in machine learning, representing the accuracy of a classification model.\n",
    "# It displays the number of true positives, true negatives, false positives, and false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79212275-52d4-4875-b7bd-4ebdd1fb4fe7",
   "metadata": {},
   "source": [
    "## 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f42679-503b-4b23-a147-31d9fa3de6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification accuracy alone can be misleading if you have an unequal number of observations in each class or if you have more than two\n",
    "# classes in your dataset. Calculating a confusion matrix can give you a better idea of what your classification model is getting right and\n",
    "# what types of errors it is making."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
