{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f5bb95-0ab5-43c0-b6ae-8de0e51a86e7",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba0ba57-3d8a-44b0-a7a0-8aac7e5e4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting in Machine Learning:\n",
    "# A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data,\n",
    "# i.e., it only performs well on training data but performs poorly on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae5e600-8eee-4a9c-99be-8b8fb0547fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasons for Underfitting:\n",
    "\n",
    "# High bias and low variance.\n",
    "# The size of the training dataset used is not enough.\n",
    "# The model is too simple.\n",
    "# Training data is not cleaned and also contains noise in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf09e9-4e03-40d6-9bde-2766b4e2ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting in Machine Learning:\n",
    "\n",
    "#A statistical model is said to be overfitted when the model does not make accurate predictions on testing data.\n",
    "# When a model gets trained with so much data, it starts learning from the noise and inaccurate data entries in our data set.\n",
    "# And when testing with test data results in High varianc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b1c88-a3cd-41c8-b47d-22a357d1e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasons for Overfitting:\n",
    "\n",
    "# High variance and low bias.\n",
    "# The model is too complex.\n",
    "# The size of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fdc0c-5860-4f84-89f4-2129fc9d42b5",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a32009-6c7e-4013-84e4-3f093ffe9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can prevent overfitting by:\n",
    "\n",
    "# Early stopping. Early stopping pauses the training phase before the machine learning model learns the noise in the data. ...\n",
    "# Pruning. \n",
    "# Regularization.\n",
    "# Ensembling.\n",
    "# Data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02176c-58be-442a-98ce-b51cb7979f8d",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f1f6c-3496-4c63-9d37-4725da6289c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting in Machine Learning:\n",
    "\n",
    "# Its occurrence simply means that our model or the algorithm does not fit the data well enough.\n",
    "# It usually happens when we have less data to build an accurate model and also when we try to build a linear model with fewer non-linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea49c8-5ab9-4607-ad30-8fc7922e7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting, the counterpart of overfitting, happens when a machine learning model is not complex enough to accurately capture relationships between a dataset's\n",
    "# features and a target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c4170-fa4b-4ff3-8a50-a8ef8a3ce6d5",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5f7ad-b20b-455e-bc93-0309590ca6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias: Assumptions made by a model to make a function easier to learn. It is actually the error rate of the training data. When the error rate has a high value,\n",
    "# we call it High Bias and when the error rate has a low value, we call it low Bias.\n",
    "\n",
    "\n",
    "# Variance: The difference between the error rate of training data and testing data is called variance.If the difference is high then it’s called high variance and\n",
    "# when the difference in errors is low then it’s called low variance. Usually, we want to make a low variance for generalized our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a88bc7-5cad-496f-9332-c1a7aafedf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In statistics and machine learning, the bias–variance tradeoff is the property of a model that the variance of the parameter estimated across samples can be\n",
    "# reduced by increasing the bias in the estimated parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed048e2d-13a7-47df-b960-2c585198e463",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7556625-4bd0-4150-bce4-8273e0875714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Techniques to Reduce Underfitting:\n",
    "\n",
    "\n",
    "# Increase model complexity.\n",
    "# Increase the number of features, performing feature engineering.\n",
    "# Remove noise from the data.\n",
    "# Increase the number of epochs or increase the duration of training to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999fc955-06e4-4a01-b065-20b28501ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Techniques to Reduce Overfitting:\n",
    "    \n",
    "    \n",
    "# Increase training data.\n",
    "# Reduce model complexity.\n",
    "# Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training).\n",
    "# Ridge Regularization and Lasso Regularization.\n",
    "# Use dropout for neural networks to tackle overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a063bad-51ef-454d-a853-5ab36d9f86de",
   "metadata": {},
   "source": [
    "## 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16365a76-1241-4f2b-b700-bf970dc24229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of high-bias machine learning algorithms include: Linear Regression, Linear Discriminant Analysis and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a113ba-b1eb-48ed-b8dd-078e43010ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High variance may result from an algorithm modeling the random noise in the training data (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb85647d-da1f-40db-8d33-b458e1002386",
   "metadata": {},
   "source": [
    "## 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a2ae5-6e87-4be1-af52-6571790503b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  What is Regularization in Machine Learning? Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting.21-F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dd4b4-0dad-422e-8345-d2d7ee07fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify loss function: In these regularization techniques, the loss function under which the model is optimized is modified to directly \n",
    "#                      take into account the norm of the learned parameters or the output distribution.\n",
    "# Modify sampling method:\n",
    "# Modify training algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535b7ca-499c-42c1-8444-c37812d0c282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423d9d5-38ae-43c0-8023-8fec771775d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4c802-3678-40a7-a8bc-a6c6b6b298f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610fa0b-e9e8-4dc2-9a74-3fd301c30293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9caf251-742f-47a5-80a2-a158b9eef634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
