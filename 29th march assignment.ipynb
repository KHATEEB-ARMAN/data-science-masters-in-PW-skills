{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0645bb0d-4590-4c4c-b2e5-9f54b75e73f0",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cff590-6ce4-4768-8e11-3bcf33969de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression, or the Least Absolute Shrinkage and Selection Operator, is also a modification of linear regression.\n",
    "# In Lasso, the loss function is modified to minimize the complexity of the model by limiting the sum of the absolute values \n",
    "# of the model coefficients (also called the l1-norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16147d8e-0bd7-4a1a-b53e-a0a94555c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso regression takes the magnitude of the coefficients, ridge regression takes the square of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3769c98d-44f3-47a7-82ed-a07f9dbf11be",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1729e-96c3-41df-8392-ace6f6909239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main advantage of a LASSO regression model is that it has the ability to set the coefficients for features it does not consider\n",
    "# interesting to zero. This means that the model does some automatic feature selection to decide which features should and should not\n",
    "# be included on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c98b4f-811e-4c56-bb67-3eb950f9d72d",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9600d5-5109-4fd1-815d-131467792b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients can be used to understand the impact of each feature on the target variable, and also help in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5fb3d-07e3-454b-a210-834ed2ac55ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  In this case, we can see that some of the coefficients are zero, indicating that those features may not be important in predicting\n",
    "# the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1873fe25-5a49-40b0-a144-784b5fbca55e",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87b7cf-36c4-483c-88b5-62321f21e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tuning parameter (Î»), sometimes called a penalty parameter, controls the strength of the penalty term in ridge regression\n",
    "# and lasso regression. It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d74df27-848d-46f6-8995-5c4f642b58f6",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407da13e-7d8d-4bf8-8716-8abc60f9d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes\n",
    "# The ordinary lasso penalty has been extensively used in the framework of linear regression models; however, sufficient results\n",
    "# have not been obtained for nonlinear regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9cfc5e-43cf-460d-a56f-272a3ff21959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We propose imposing a weighted lasso penalty on a nonlinear regression model and thereby selecting the number of basis functions\n",
    "# effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1791376e-d5f5-4844-96f7-a637f50a4963",
   "metadata": {},
   "source": [
    "## 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7527d-7ca7-4aca-b7dd-1befc5d6077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The difference between ridge and lasso regression is that it tends to make coefficients to absolute zero \n",
    "#     as compared to Ridge which never sets the value of coefficient to absolute zero.\n",
    "# 2. Lasso will eliminate many features, and reduce overfitting in your linear model. Ridge will reduce the impact of\n",
    "#    features that are not important in predicting your y values.\n",
    "# 3.Elastic Net combines feature elimination from Lasso and feature coefficient reduction from the Ridge model to improve your\n",
    "#   model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca9b1b-5938-41b5-8ba2-617a205a4484",
   "metadata": {},
   "source": [
    "## 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605af01-eb3c-498d-98b1-d2ef416988a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression is a linear regression technique with L1 prior as a regularize. The idea is to reduce the multicollinearity\n",
    "# by regularization by reducing the coefficients of the feature that are multicollinear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aab75b-32d4-4450-9cff-86a505eee501",
   "metadata": {},
   "source": [
    "## 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c43cd-8d3c-490d-886c-216c43dd66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step to build a lasso model is to find the optimal lambda value using the code below.\n",
    "# For lasso regression, the alpha value is 1. The output is the best cross-validated lambda, which comes out to be 0.001."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
