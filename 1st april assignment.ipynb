{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0683e72f-92e6-4431-9030-27ad5ccc8ecf",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02be5729-cd45-4710-a4e4-6634f61a0ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Linear Regression is used to handle regression problems whereas Logistic regression is used to handle the classification problems. Linear regression provides a continuous output but Logistic regression provides discreet output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51e7eb-02ad-4229-be13-a42f37645bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression is a supervised regression model.\n",
    "# Logistic Regression is a supervised classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3745482-bfa3-4bae-a986-3ae216c10bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Linear Regression, we predict the value by an integer number.\n",
    "# In Logistic Regression, we predict the value by 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547624f-1cfe-4758-beb2-a59aae57f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here no threshold value is needed.\n",
    "# Here  threshold value is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76e6cf-3609-4f8a-ae8b-afa94cc394a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here when we plot the training datasets, a straight line can be drawn that touches maximum plots.\n",
    "\n",
    "# Any change in the coefficient leads to a change in both the direction and the steepness of the logistic function.\n",
    "# It means positive slopes result in an S-shaped curve and negative slopes result in a Z-shaped curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ebd842-b834-4703-a40f-8df81600d7db",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a4e542-46f7-4055-91d2-731474f0868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Logistic Regression the cost function we use is also known as the cross entropy or the log loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de2950-e180-4af8-a2ab-87803e7730b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Cost function is used to gauge the performance of the Machine Learning model. A Machine Learning model devoid of the Cost function is futile.\n",
    "# Cost Function helps to analyze how well a Machine Learning model performs. A Cost function basically compares the predicted values with the actual\n",
    "# values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29dd998-e7f0-483d-ab77-70e5afe553ca",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e4f5fb-0d93-4db7-ad72-f4304ee668f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization helps you avoid overfitting by adding a penalty term to the cost function of your model, which measures how well your model fits\n",
    "# the data. The penalty term reduces the complexity of your model by shrinking or eliminating some of the coefficients of your input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c67b6-6da1-4eff-baff-ddb069f70038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Regularization in machine learning is the process of regularizing the parameters that constrain, regularizes, or shrinks the coefficient estimates\n",
    "# towards zero. In other words, this technique discourages learning a more complex or flexible model, avoiding the risk of Overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff189ad7-1222-4a44-9b01-63a8f29e4673",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074fb95-e720-4b20-8d84-ad544233ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ROC curve is used to assess the overall diagnostic performance of a test and to compare the performance of two or more diagnostic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d4cd1-c494-4db2-9580-cda35d2b20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ROC curve is produced by calculating and plotting the true positive rate against the false positive rate for a single classifier\n",
    "# at a variety of thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401e29b-cc98-41a7-9ece-48a8472ad141",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85df7a4-1721-42d6-8c9e-a11524bca434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several types of statistical tests that can be used for filter feature selection, including chi-square, ANOVA, and mutual information.\n",
    "# These tests measure the degree of association between the features and the target variable, and can help identify the most relevant features for\n",
    "# the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133e4bf-0dd5-4b58-bb46-d0f5f61f35e1",
   "metadata": {},
   "source": [
    "## 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "324d7275-6f9b-448f-8fd0-6f7a67be19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Proper Evaluation Metric. The accuracy of a classifier is the total number of correct predictions by the classifier divided by the total number of predictions. ...\n",
    "# Resampling (Oversampling and Undersampling) \n",
    "# SMOTE. \n",
    "# BalancedBaggingClassifier. \n",
    "# Threshold moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0a42c-d3cd-42d9-8c76-59494d6240eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the performance metric.\n",
    "# Change the algorithm. \n",
    "# Resampling Techniques — Oversample minority class.\n",
    "# Resampling techniques — Undersample majority class.\n",
    "# Generate synthetic samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
